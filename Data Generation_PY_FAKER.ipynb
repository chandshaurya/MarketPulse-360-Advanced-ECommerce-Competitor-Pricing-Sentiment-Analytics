{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c353d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "faker = Faker('en_IN')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ---------- PARAMETERS ----------\n",
    "NUM_PRODUCTS = 2000\n",
    "NUM_CUSTOMERS = 50000\n",
    "NUM_SALES_PER_PRODUCT = 365\n",
    "CATEGORIES = [\"Electronics\", \"Fashion\", \"Home Appliances\", \"Books\", \"Beauty\", \"Sports\"]\n",
    "BRANDS = [\"BrandX\", \"BrandY\", \"BrandZ\", \"Alpha\", \"Beta\", \"Gamma\"]\n",
    "CHANNELS = [\"Organic\", \"Paid\", \"Referral\", \"Social Media\", \"Email Marketing\"]\n",
    "DAILY_SALE_PROBABILITY = 0.4  # 40% of days have sales\n",
    "\n",
    "# ---------- 1. PRODUCTS ----------\n",
    "products = []\n",
    "for pid in range(1, NUM_PRODUCTS + 1):\n",
    "    products.append({\n",
    "        \"ProductID\": pid,\n",
    "        \"ProductName\": faker.catch_phrase(),\n",
    "        \"Category\": random.choice(CATEGORIES),\n",
    "        \"Brand\": random.choice(BRANDS),\n",
    "        \"BasePrice\": round(random.uniform(200, 50000), 2),\n",
    "        \"LaunchDate\": faker.date_between(start_date=\"-2y\", end_date=\"today\")\n",
    "    })\n",
    "df_products = pd.DataFrame(products)\n",
    "df_products['LaunchDate'] = pd.to_datetime(df_products['LaunchDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ed886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2. CUSTOMERS ----------\n",
    "customers = []\n",
    "for cid in range(1, NUM_CUSTOMERS + 1):\n",
    "    customers.append({\n",
    "        \"CustomerID\": cid,\n",
    "        \"Name\": faker.name(),\n",
    "        \"Gender\": random.choice([\"Male\", \"Female\"]),\n",
    "        \"City\": faker.city(),\n",
    "        \"State\": faker.state(),\n",
    "        \"Email\": faker.email(),\n",
    "        \"RegistrationDate\": faker.date_between(start_date=\"-3y\", end_date=\"today\"),\n",
    "        \"LoyaltyTier\": random.choice([\"Gold\", \"Silver\", \"Bronze\"])\n",
    "    })\n",
    "df_customers = pd.DataFrame(customers)\n",
    "df_customers['RegistrationDate'] = pd.to_datetime(df_customers['RegistrationDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d636bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. SALES (Optimized & Capped at ~5 lakh) ----------\n",
    "sales = []\n",
    "start_date = datetime(2024, 1, 1)\n",
    "\n",
    "# Target size\n",
    "MAX_SALES_ROWS = 500_000\n",
    "rows_generated = 0\n",
    "\n",
    "for _, product in df_products.iterrows():\n",
    "    if rows_generated >= MAX_SALES_ROWS:\n",
    "        break  # stop once we hit 5 lakh rows\n",
    "\n",
    "    if random.random() < 0.01:\n",
    "        continue\n",
    "\n",
    "    eligible_ids = df_customers.loc[\n",
    "        df_customers['RegistrationDate'] <= product['LaunchDate'], 'CustomerID'\n",
    "    ].values\n",
    "    if eligible_ids.size == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly pick some sale days for this product\n",
    "    sale_days = sorted(random.sample(range(NUM_SALES_PER_PRODUCT), k=random.randint(50, 200)))\n",
    "\n",
    "    for day in sale_days:\n",
    "        if rows_generated >= MAX_SALES_ROWS:\n",
    "            break\n",
    "\n",
    "        sale_date = start_date + timedelta(days=day)\n",
    "        seasonality_factor = 1.5 if sale_date.month in [10, 11, 12] else 1.0\n",
    "        discount = round(random.uniform(0, 0.3), 2)\n",
    "        competitor_price = product[\"BasePrice\"] * random.uniform(0.9, 1.1)\n",
    "        units_sold = int(np.random.poisson(5) * seasonality_factor * (1 + discount))\n",
    "        returns = int(units_sold * random.uniform(0, 0.05))\n",
    "        net_units = units_sold - returns\n",
    "\n",
    "        # Outlier injection\n",
    "        if random.random() < 0.0005:\n",
    "            net_units *= 50\n",
    "        if random.random() < 0.0005:\n",
    "            net_units = -abs(net_units)\n",
    "        revenue = round(net_units * product[\"BasePrice\"] * (1 - discount), 2)\n",
    "        if random.random() < 0.0005:\n",
    "            revenue = 0\n",
    "\n",
    "        sales.append({\n",
    "            \"ProductID\": product[\"ProductID\"],\n",
    "            \"CustomerID\": random.choice(eligible_ids),\n",
    "            \"Date\": sale_date,\n",
    "            \"UnitsSold\": net_units,\n",
    "            \"Returns\": returns,\n",
    "            \"Discount\": discount,\n",
    "            \"OurPrice\": round(product[\"BasePrice\"] * (1 - discount), 2),\n",
    "            \"CompetitorPrice\": round(competitor_price, 2),\n",
    "            \"Revenue\": revenue,\n",
    "            \"AcquisitionChannel\": random.choice(CHANNELS)\n",
    "        })\n",
    "        rows_generated += 1\n",
    "\n",
    "df_sales = pd.DataFrame(sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e36daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4. REVIEWS ----------\n",
    "reviews = []\n",
    "if not df_sales.empty:\n",
    "    product_purchasers = df_sales.groupby('ProductID')['CustomerID'].unique().to_dict()\n",
    "    purchase_dates = df_sales.groupby(['ProductID', 'CustomerID'])['Date'].min().to_dict()\n",
    "else:\n",
    "    product_purchasers = {}\n",
    "    purchase_dates = {}\n",
    "\n",
    "for product_id, purchasers in product_purchasers.items():\n",
    "    if len(purchasers) == 0:\n",
    "        continue\n",
    "    num_reviews = int(len(purchasers) * random.uniform(0.05, 0.3))\n",
    "    for _ in range(num_reviews):\n",
    "        customer_id = random.choice(purchasers)\n",
    "        purchase_date = purchase_dates.get((product_id, customer_id), datetime(2024, 1, 1))\n",
    "        review_date = faker.date_between(start_date=purchase_date, end_date=\"today\")\n",
    "\n",
    "        review_text = faker.sentence(nb_words=12)\n",
    "        sentiment_score = analyzer.polarity_scores(review_text)[\"compound\"]\n",
    "        rating = min(max(int((sentiment_score + 1) * 2.5 + random.uniform(-0.5, 0.5)), 1), 5)\n",
    "\n",
    "        reviews.append({\n",
    "            \"ProductID\": product_id,\n",
    "            \"CustomerID\": customer_id,\n",
    "            \"ReviewDate\": review_date,\n",
    "            \"Rating\": rating,\n",
    "            \"ReviewText\": review_text,\n",
    "            \"SentimentScore\": sentiment_score\n",
    "        })\n",
    "df_reviews = pd.DataFrame(reviews)\n",
    "\n",
    "# ---------- 5. MISSING DATA ----------\n",
    "for col in [\"Discount\", \"OurPrice\", \"CompetitorPrice\", \"AcquisitionChannel\"]:\n",
    "    if not df_sales.empty:\n",
    "        df_sales.loc[df_sales.sample(frac=0.01).index, col] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e281cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products: 2000 rows\n",
      "Customers: 50000 rows\n",
      "Sales: 248471 rows\n",
      "Reviews: 42719 rows\n"
     ]
    }
   ],
   "source": [
    "# ---------- SAVE ----------\n",
    "df_products.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\products.csv\", index=False)\n",
    "df_customers.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\customers.csv\", index=False)\n",
    "df_sales.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\sales.csv\", index=False)\n",
    "df_reviews.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\reviews.csv\", index=False)\n",
    "\n",
    "# ---------- SUMMARY ----------\n",
    "print(f\"Products: {len(df_products)} rows\")\n",
    "print(f\"Customers: {len(df_customers)} rows\")\n",
    "print(f\"Sales: {len(df_sales)} rows\")\n",
    "print(f\"Reviews: {len(df_reviews)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39443e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2. CUSTOMERS (State-City Mapping) ----------\n",
    "state_city_map = {\n",
    "    \"Andhra Pradesh\": [\"Visakhapatnam\", \"Vijayawada\", \"Guntur\"],\n",
    "    \"Bihar\": [\"Patna\", \"Gaya\", \"Bhagalpur\"],\n",
    "    \"Delhi\": [\"New Delhi\", \"Dwarka\", \"Rohini\"],\n",
    "    \"Gujarat\": [\"Ahmedabad\", \"Surat\", \"Vadodara\"],\n",
    "    \"Karnataka\": [\"Bengaluru\", \"Mysuru\", \"Mangaluru\"],\n",
    "    \"Kerala\": [\"Kochi\", \"Thiruvananthapuram\", \"Kozhikode\"],\n",
    "    \"Maharashtra\": [\"Mumbai\", \"Pune\", \"Nagpur\"],\n",
    "    \"Punjab\": [\"Ludhiana\", \"Amritsar\", \"Jalandhar\"],\n",
    "    \"Rajasthan\": [\"Jaipur\", \"Jodhpur\", \"Udaipur\"],\n",
    "    \"Tamil Nadu\": [\"Chennai\", \"Coimbatore\", \"Madurai\"],\n",
    "    \"Telangana\": [\"Hyderabad\", \"Warangal\", \"Nizamabad\"],\n",
    "    \"Uttar Pradesh\": [\"Lucknow\",\"Gorakhpur\", \"Kanpur\", \"Varanasi\"],\n",
    "    \"West Bengal\": [\"Kolkata\", \"Howrah\", \"Durgapur\"]\n",
    "}\n",
    "\n",
    "states = list(state_city_map.keys())\n",
    "\n",
    "customers = []\n",
    "for cid in range(1, NUM_CUSTOMERS + 1):\n",
    "    state = random.choice(states)\n",
    "    city = random.choice(state_city_map[state])\n",
    "    customers.append({\n",
    "        \"CustomerID\": cid,\n",
    "        \"Name\": faker.name(),\n",
    "        \"Gender\": random.choice([\"Male\", \"Female\"]),\n",
    "        \"City\": city,\n",
    "        \"State\": state,\n",
    "        \"Email\": faker.email(),\n",
    "        \"RegistrationDate\": faker.date_between(start_date=\"-3y\", end_date=\"today\"),\n",
    "        \"LoyaltyTier\": random.choice([\"Gold\", \"Silver\", \"Bronze\"])\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customers)\n",
    "df_customers['RegistrationDate'] = pd.to_datetime(df_customers['RegistrationDate'])\n",
    "\n",
    "df_customers.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6c6b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated reviews.csv with new Rating & SentimentScore columns saved as reviews_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\reviews.csv\")\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# --- Update Ratings ---\n",
    "# More realistic distribution (skewed towards positive but still some negatives)\n",
    "rating_choices = [1, 2, 3, 4, 5]\n",
    "rating_weights = [0.10, 0.15, 0.20, 0.30, 0.25]  # adjust to your needs\n",
    "df['Rating'] = np.random.choice(rating_choices, size=len(df), p=rating_weights)\n",
    "\n",
    "# --- Update Sentiment Score ---\n",
    "# Simple mapping: generate sentiment aligned with rating\n",
    "def generate_sentiment(rating):\n",
    "    if rating == 1:\n",
    "        return round(random.uniform(-0.8, -0.4), 3)   # strong negative\n",
    "    elif rating == 2:\n",
    "        return round(random.uniform(-0.4, -0.1), 3)   # mild negative\n",
    "    elif rating == 3:\n",
    "        return round(random.uniform(-0.1, 0.1), 3)    # neutral / mixed\n",
    "    elif rating == 4:\n",
    "        return round(random.uniform(0.1, 0.4), 3)     # positive\n",
    "    elif rating == 5:\n",
    "        return round(random.uniform(0.4, 0.8), 3)     # strong positive\n",
    "\n",
    "df['SentimentScore'] = df['Rating'].apply(generate_sentiment)\n",
    "\n",
    "# Save updated dataset\n",
    "df.to_csv(\"D:\\\\powerbi\\\\projects\\\\Upcoming Project\\\\MarketPulse 360  Advanced ECommerce Competitor, Pricing & Sentiment Analytics\\\\reviews_updated.csv\", index=False)\n",
    "\n",
    "print(\"✅ Updated reviews.csv with new Rating & SentimentScore columns saved as reviews_updated.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
